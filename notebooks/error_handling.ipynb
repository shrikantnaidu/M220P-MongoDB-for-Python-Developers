{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://s3.amazonaws.com/edu-static.mongodb.com/lessons/M220/notebook_assets/screen_align.png\" style=\"margin: 0 auto;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align: center; font-size=58px;\">Writes with Error Handling</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "At this point we've gotten pretty comfortable writing data to Mongo, creating and updating with different durabilities. We've even configured the driver to change the way our writes are perceived. But there are still times when the writes we send to the server will result in an error, and we've briefly discussed the way our application can deal with these errors.\n",
    "\n",
    "In this lesson we're gonna encounter some of the basic errors in the Pymongo driver, and how to handle these errors in a way that makes our application more consistent and reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient, errors\n",
    "uri = \"<your_atlas_uri>\"\n",
    "mc = MongoClient(uri)\n",
    "lessons = mc.lessons\n",
    "shipments = lessons.shipments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So here's a URI string connecting to our Atlas cluster, and I've initialized a client with that string.\n",
    "\n",
    "We're using a new collection called `shipments`, and the scenario for this lesson is that our application is a clothing manufacturer that also handles the shipping for their clothing items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "<your_atlas_uri>:27017: [Errno 11001] getaddrinfo failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0f7534666fd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mshipments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mcities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;34m\"Atlanta\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"New York\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Miami\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Chicago\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Los Angeles\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Seattle\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Dallas\"\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shrik\\desktop\\mongodb-university\\mflix-python\\mflix_venv\\lib\\site-packages\\pymongo\\collection.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, session)\u001b[0m\n\u001b[0;32m   1090\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_concern\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m             self.read_concern)\n\u001b[1;32m-> 1092\u001b[1;33m         \u001b[0mdbo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m     def _delete(\n",
      "\u001b[1;32mc:\\users\\shrik\\desktop\\mongodb-university\\mflix-python\\mflix_venv\\lib\\site-packages\\pymongo\\database.py\u001b[0m in \u001b[0;36mdrop_collection\u001b[1;34m(self, name_or_collection, session)\u001b[0m\n\u001b[0;32m    746\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_purge_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_socket_for_writes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msock_info\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m             return self._command(\n\u001b[0;32m    750\u001b[0m                 \u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'drop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shrik\\desktop\\mongodb-university\\mflix-python\\mflix_venv\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_socket_for_writes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_socket_for_writes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m         \u001b[0mserver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_topology\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_server\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwritable_server_selector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1086\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shrik\\desktop\\mongodb-university\\mflix-python\\mflix_venv\\lib\\site-packages\\pymongo\\topology.py\u001b[0m in \u001b[0;36mselect_server\u001b[1;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[0;32m    222\u001b[0m         return random.choice(self.select_servers(selector,\n\u001b[0;32m    223\u001b[0m                                                  \u001b[0mserver_selection_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m                                                  address))\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     def select_server_by_address(self, address,\n",
      "\u001b[1;32mc:\\users\\shrik\\desktop\\mongodb-university\\mflix-python\\mflix_venv\\lib\\site-packages\\pymongo\\topology.py\u001b[0m in \u001b[0;36mselect_servers\u001b[1;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             server_descriptions = self._select_servers_loop(\n\u001b[1;32m--> 183\u001b[1;33m                 selector, server_timeout, address)\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             return [self.get_server_by_address(sd.address)\n",
      "\u001b[1;32mc:\\users\\shrik\\desktop\\mongodb-university\\mflix-python\\mflix_venv\\lib\\site-packages\\pymongo\\topology.py\u001b[0m in \u001b[0;36m_select_servers_loop\u001b[1;34m(self, selector, timeout, address)\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnow\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 raise ServerSelectionTimeoutError(\n\u001b[1;32m--> 199\u001b[1;33m                     self._error_message(selector))\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_opened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mServerSelectionTimeoutError\u001b[0m: <your_atlas_uri>:27017: [Errno 11001] getaddrinfo failed"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "shipments.drop()\n",
    "\n",
    "cities = [ \"Atlanta\", \"New York\", \"Miami\", \"Chicago\", \"Los Angeles\", \"Seattle\", \"Dallas\" ]\n",
    "products = [ \"shoes\", \"pants\", \"shirts\", \"hats\", \"socks\" ]\n",
    "quantities = [ 10, 20, 40, 80, 160, 320, 640, 1280, 2560 ]\n",
    "docs = []\n",
    "\n",
    "for truck_id in range(30):\n",
    "    source = random.choice(cities)\n",
    "    destination = random.choice([c for c in cities if c != source])\n",
    "    product = random.choice(products)\n",
    "    quantity = random.choice(quantities)\n",
    "    \n",
    "    doc = {\n",
    "        \"truck_id\": truck_id,\n",
    "        \"source\": source,\n",
    "        \"destination\": destination,\n",
    "        \"product\": product,\n",
    "        \"quantity\": quantity\n",
    "    }\n",
    "    \n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "insert_response = shipments.insert_many(docs)\n",
    "shipments.count_documents({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This is a short script that's gonna create some test data for the clothing manufacturer. This is included in this notebook so you can test it out yourself.\n",
    "\n",
    "You can see the documents we're producing have 5 fields each, with this `truck_id` determined by the iteration of our loop (point to `truck_id`). The (point) source and destination are both derived from this `cities` array, and this (point to `destination`) part will make sure that the destination city is different from the source.\n",
    "\n",
    "Each shipment also has a product and a quantity, but the part we're gonna focus on is this (point) `truck_id` field. This is gonna record the truck currently allocated for this shipment, so that truck can be considered unavailable for any another shipments. This way when a new shipment comes in, we can make sure the truck that gets assigned to that shipment isn't already doing another one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "shipments.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Right now this loop only has 30 iterations (point to the loop) so we have exactly 30 documents in the `shipments` collection. If we take a look at one of them...\n",
    "\n",
    "(run command)\n",
    "\n",
    "Then we can see that they each have these five fields. The assumption I'm making for this data is that, while this (point) document exists in the collection, the shipment is still ongoing. When this shipment is complete, we would delete this document, or maybe add a flag to the document like `{ completed: True }`.\n",
    "\n",
    "This means that 30 documents in the `shipments` collection means 30 shipments that are happening right now. And if we tried to insert a new shipment, it has to have a unique `truck_id` (point). This way each truck is only assigned to one shipment at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "shipments.create_index(\"truck_id\", unique=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So this is the way we're gonna enforce uniqueness among these `truck_id`s. This is called a unique index, which will create an index on the `truck_id` field, and also make sure that there are no duplicate `truck_id`s.\n",
    "\n",
    "(enter command)\n",
    "\n",
    "And it created this index called `truck_id_1`, the 1 meaning that the index is sorted in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "doc = {\n",
    "    \"source\": \"New York\",\n",
    "    \"destination\": \"Atlanta\",\n",
    "    \"truck_id\": 4,\n",
    "    \"product\": \"socks\",\n",
    "    \"quantity\": 40\n",
    "}\n",
    "\n",
    "try:\n",
    "    res = shipments.insert_one(doc)\n",
    "    print(res.inserted_id)\n",
    "except errors.DuplicateKeyError:\n",
    "    truck_id = doc[\"truck_id\"]\n",
    "    print(f\"Truck #{truck_id} is currently performing a shipment. Please select another truck.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Here's an example of a shipment being added to our collection. We want to ship 40 socks from New York to Atlanta, and we've chosen to assign truck 4 to perform this shipment. This (point) truck number could have been user input, or something determined by our application, but either way this is going to cause a `DuplicateKeyError` because we already have a shipment assigned to truck (point) 4.\n",
    "\n",
    "(enter command)\n",
    "\n",
    "So using the try-except block, our program prints out a message when a `DuplicateKeyError` is thrown. The message tells us that the truck we wanted to use has already been sent out. So the application allows the insert to fail, and then sends an error message up to the user to choose another truck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "trucks = lessons.trucks\n",
    "trucks.drop()\n",
    "\n",
    "trucks.insert_many([\n",
    "    { \"_id\": i, \"license\": \"\".join(random.choice(string.ascii_uppercase + string.digits) for _ in range(7)) } for i in range(50)\n",
    "])\n",
    "trucks.count_documents({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "But we can actually be a little more proactive in handling this error, if we know about the other trucks who are available for this job.\n",
    "\n",
    "Here's a new collection called `trucks`, which we're gonna use to find another available truck. This should insert exactly 50 documents into this collection...\n",
    "\n",
    "(enter command)\n",
    "\n",
    "And it looks like it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "trucks.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The documents each only have two fields: an `_id` from 0 to 49 (point), which will relate to the `truck_id` from the `shipments` collection. And I've assigned a random string of 7 uppercase letters and numbers to be the license plate number, although actually some US states only allow 6 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "doc = {\n",
    "    \"source\": \"New York\",\n",
    "    \"destination\": \"Atlanta\",\n",
    "    \"truck_id\": 4,\n",
    "    \"product\": \"socks\",\n",
    "    \"quantity\": 40\n",
    "}\n",
    "\n",
    "try:\n",
    "    res = shipments.insert_one(doc)\n",
    "    print(res.inserted_id)\n",
    "except errors.DuplicateKeyError:\n",
    "    busy_trucks = set(shipments.distinct(\"truck_id\"))\n",
    "    all_trucks = set(trucks.distinct(\"_id\"))\n",
    "    available_trucks = all_trucks.difference(busy_trucks)\n",
    "    old_truck_id = doc[\"truck_id\"]\n",
    "    if available_trucks:\n",
    "        chosen_truck = random.choice(list(available_trucks))\n",
    "        new_truck_id = doc[\"truck_id\"] = chosen_truck\n",
    "        res = shipments.insert_one(doc)\n",
    "        print(f\"Truck #{old_truck_id} is currently performing a shipment. Truck #{new_truck_id} has been sent out instead.\")\n",
    "    else:\n",
    "        print(f\"Truck #{old_truck_id} is currently performing a shipment. Could not find another truck.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So the error handling now is a little more proactive.\n",
    "\n",
    "Instead of just surfacing an error to the user, the application actually chooses a new truck, sends out that truck, and then alerted the user that the action was performed, just by a different vehicle.\n",
    "\n",
    "(enter command)\n",
    "\n",
    "In this case we tried to send truck number 4 out, but it wasn't available. So we decided to try sending another truck.\n",
    "\n",
    "But this time we were a little more careful. We performed a couple queries to figure out all the vehicles that are available for this shipment.\n",
    "\n",
    "We pulled the `truck_id`s from all the trucks into a set, and then pulled all the `truck_id`s from shipments into a set, and then took the difference to figure out which `truck_id`s were not already out on a shipment.\n",
    "\n",
    "This check, to see which trucks are available, is actually somewhat expensive as these two `distinct()` queries require two database round trips. Because of this, the application takes a pretty lazy approach here assigning trucks to shipments, and doesn't do any round trips until the truck it tries to send out comes up unavailable.\n",
    "\n",
    "This might be suitable if the collisions won't occur very often. Which is to say, trucks are usually available when we request them. But on the rare occasions they are not available, we do a little extra work, and then send out a truck that we KNOW, with some certainty, will be available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "* `DuplicateKeyError` can occur on `_id` as well as fields in unique indexes\n",
    "* When handling errors, determine how fatal the error is\n",
    "    * Should this error be returned to the user?\n",
    "    * Can we react to this error in a useful way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So in this lesson we demonstrated how to handle a specific `DuplicateKeyError`, and it's important to remember that this error usually occurs on `_id`, which is unique by default. But it also pertains to fields contained in a unique index, like the index we had on `truck_id`.\n",
    "\n",
    "Really when handling these errors we want to think about how much we can do after receiving the error. If there's nothing we can do in response, if this error is truly fatal, we should just return it to the user.\n",
    "\n",
    "But if we can do something, as was the case with the `shipments` collection, we should try to handle the error in a more flexible way. In the example, the error was that the truck we tried to reserve was already in use. But at that time, the program actually had the resources to determine which trucks were still available, so it sent one of those trucks out instead."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
